{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-1_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagayoshi3/deep_learning_practice/blob/master/4_1_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j32Gy-DuKqZW",
        "colab_type": "text"
      },
      "source": [
        "# GANの体験\n",
        "\n",
        "## データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fuZZpShKuw3",
        "colab_type": "code",
        "outputId": "1d77e1d2-7908-4c68-fa87-117b1ac607a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def load_mnist(dim=3, data='mnist'):\n",
        "    img_rows, img_cols = 28, 28\n",
        "    \n",
        "    if data == 'mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    else:\n",
        "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "    \n",
        "    if dim == 3:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    else:\n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows*img_cols)\n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows*img_cols)\n",
        "        \n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "    y_train = np.eye(10)[y_train]\n",
        "    y_test = np.eye(10)[y_test]\n",
        "    \n",
        "    return  x_train, x_test, y_train, y_test\n",
        "\n",
        "\n",
        "def plot_mnist(n_ex=10,dim=(2,5), figsize=(8,4)):\n",
        "    noise = np.random.uniform(0,1,size=[n_ex,100])\n",
        "    generated_images = generator.predict(noise)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generated_images.shape[0]):\n",
        "        plt.subplot(dim[0],dim[1],i+1)\n",
        "        img = generated_images[i,:,:, 0]\n",
        "        plt.imshow(img, cmap='binary')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtRridRoKyZ8",
        "colab_type": "text"
      },
      "source": [
        "## モデルの構築（Generator、Discriminator）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y04HbiXdmbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Reshape, Dense, Dropout, Flatten, Activation, LeakyReLU, Conv2D, UpSampling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 画像生成器\n",
        "def Generator():\n",
        "    nch=200\n",
        "    model_input = Input(shape=[100])\n",
        "    x = Dense(nch*14*14, kernel_initializer='glorot_normal')(model_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Reshape( [14, 14, nch] )(x)\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(int(nch/2), (3, 3), padding='same', kernel_initializer='glorot_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(int(nch/4), (3, 3), padding='same', kernel_initializer='glorot_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(1, (1, 1), padding='same', kernel_initializer='glorot_uniform')(x)\n",
        "    model_output = Activation('sigmoid')(x)\n",
        "    model = Model(model_input, model_output)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# 画像識別器\n",
        "def Discriminator(shape, dropout_rate=0.25, opt=Adam(lr=1e-4)):\n",
        "    model_input = Input(shape=shape)\n",
        "    x = Conv2D(256, (5, 5), padding = 'same', kernel_initializer='glorot_uniform', strides=(2, 2))(model_input)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Conv2D(512, (5, 5), padding = 'same', kernel_initializer='glorot_uniform', strides=(2, 2))(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(256)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    model_output = Dense(2,activation='softmax')(x)\n",
        "    model = Model(model_input, model_output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def combined_network(generator, discriminator, opt=Adam(lr=1e-3)):\n",
        "    gan_input = Input(shape=[100])\n",
        "    x = generator(gan_input)\n",
        "    gan_output = discriminator(x)\n",
        "    model = Model(gan_input, gan_output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def make_trainable(net, val):\n",
        "    net.trainable = val\n",
        "    for l in net.layers:\n",
        "        l.trainable = val\n",
        "\n",
        "        \n",
        "def train(step=10000, BATCH_SIZE=128):\n",
        "    for e in tqdm(range(step)):  \n",
        "        image_batch = X_train[np.random.randint(0,X_train.shape[0],size=BATCH_SIZE),:,:,:]    \n",
        "        noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
        "        generated_images = generator.predict(noise_gen)\n",
        "        \n",
        "        make_trainable(discriminator,True)\n",
        "        \n",
        "        X = np.concatenate((image_batch, generated_images))\n",
        "        y = np.zeros([2*BATCH_SIZE,2])\n",
        "        y[:BATCH_SIZE,1] = 1\n",
        "        y[BATCH_SIZE:,0] = 1\n",
        "        \n",
        "        discriminator.train_on_batch(X,y)\n",
        "        \n",
        "        make_trainable(discriminator,False)\n",
        "    \n",
        "        noise_gen = np.random.uniform(0,1,size=[BATCH_SIZE,100])\n",
        "        y2 = np.zeros([BATCH_SIZE,2])\n",
        "        y2[:,1] = 1\n",
        "             \n",
        "        GAN.train_on_batch(noise_gen, y2 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p8GzQMMLS-h",
        "colab_type": "text"
      },
      "source": [
        "## モデルの実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4dm9gi8dqgL",
        "colab_type": "code",
        "outputId": "b6f0a581-391c-4f51-b997-1df5229a6b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        }
      },
      "source": [
        "X_train, _,_,_ = load_mnist(data='fashion')\n",
        "generator = Generator()\n",
        "discriminator = Discriminator(X_train.shape[1:])\n",
        "make_trainable(discriminator, False)\n",
        "GAN = combined_network(generator, discriminator)\n",
        "\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 38/10000 [07:18<31:40:07, 11.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cab8e6a483b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mGAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-218985f4cda6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(step, BATCH_SIZE)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmake_trainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8Z6g4Kpdrpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_mnist()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}