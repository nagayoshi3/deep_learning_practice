{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-2_Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagayoshi3/deep_learning_practice/blob/master/3_2_Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpZEBEZJTr3_",
        "colab_type": "text"
      },
      "source": [
        "# ニューラルネットワークによる翻訳\n",
        "ニューラルネットワークによる翻訳を体験してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YnCrOmGaOo7",
        "colab_type": "text"
      },
      "source": [
        "## データの取得"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5pvo-3dlfNN",
        "colab_type": "code",
        "outputId": "ecada1c2-3909-4e37-95ed-b1294e0fdf41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/d2bz2xmky5l9p8n/train.en?dl=0\n",
        "!wget https://www.dropbox.com/s/ft08ydqr6msbsfo/train.ja?dl=0\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(file_path):\n",
        "    tokenizer = Tokenizer(filters=\"\")\n",
        "    whole_texts = []\n",
        "    for line in open(file_path, encoding='utf-8'):\n",
        "        whole_texts.append(\"<s> \" + line.strip() + \" </s>\")\n",
        "        \n",
        "    tokenizer.fit_on_texts(whole_texts)\n",
        "    \n",
        "    return tokenizer.texts_to_sequences(whole_texts), tokenizer\n",
        "\n",
        "# 読み込み＆Tokenizerによる数値化\n",
        "x_train, tokenizer_en = load_data('train.en?dl=0')\n",
        "y_train, tokenizer_ja = load_data('train.ja?dl=0')\n",
        "\n",
        "show_ja=pd.read_csv('train.ja?dl=0', engine='python')\n",
        "print(show_ja)\n",
        "\n",
        "en_vocab_size = len(tokenizer_en.word_index) + 1\n",
        "ja_vocab_size = len(tokenizer_ja.word_index) + 1\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.02, random_state=42)\n",
        "\n",
        "# パディング\n",
        "x_train = pad_sequences(x_train, padding='post')\n",
        "y_train = pad_sequences(y_train, padding='post')\n",
        "\n",
        "seqX_len = len(x_train[0])\n",
        "seqY_len = len(y_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-03 12:58:40--  https://www.dropbox.com/s/d2bz2xmky5l9p8n/train.en?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/d2bz2xmky5l9p8n/train.en [following]\n",
            "--2019-11-03 12:58:40--  https://www.dropbox.com/s/raw/d2bz2xmky5l9p8n/train.en\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc8c8a128b9cdd371e519cec727b.dl.dropboxusercontent.com/cd/0/inline/AroOa6Onz61dGCqe5mvbzb9t-wPiG2w_7sevVmkrNAVf4f8iadKblPLDMFKmSssQ8mgbT3rAvu5KzQW4NWT23DB8mb89t9Fi9y478ZwjX2my6g/file# [following]\n",
            "--2019-11-03 12:58:41--  https://uc8c8a128b9cdd371e519cec727b.dl.dropboxusercontent.com/cd/0/inline/AroOa6Onz61dGCqe5mvbzb9t-wPiG2w_7sevVmkrNAVf4f8iadKblPLDMFKmSssQ8mgbT3rAvu5KzQW4NWT23DB8mb89t9Fi9y478ZwjX2my6g/file\n",
            "Resolving uc8c8a128b9cdd371e519cec727b.dl.dropboxusercontent.com (uc8c8a128b9cdd371e519cec727b.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to uc8c8a128b9cdd371e519cec727b.dl.dropboxusercontent.com (uc8c8a128b9cdd371e519cec727b.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1701356 (1.6M) [text/plain]\n",
            "Saving to: ‘train.en?dl=0’\n",
            "\n",
            "train.en?dl=0       100%[===================>]   1.62M  6.28MB/s    in 0.3s    \n",
            "\n",
            "2019-11-03 12:58:41 (6.28 MB/s) - ‘train.en?dl=0’ saved [1701356/1701356]\n",
            "\n",
            "--2019-11-03 12:58:42--  https://www.dropbox.com/s/ft08ydqr6msbsfo/train.ja?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ft08ydqr6msbsfo/train.ja [following]\n",
            "--2019-11-03 12:58:42--  https://www.dropbox.com/s/raw/ft08ydqr6msbsfo/train.ja\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc67ec2ded65da0b5ae1fdee19b0.dl.dropboxusercontent.com/cd/0/inline/ArpPUtKM4Wb5qHbzTWkCkPVge-jgcfWIVHwzGp3Ij2SAVLTv7wgfvb0RwIKr6CjQMu-qU8xwOqOCnW98gbub_tEvJ19tTj1Z60joFfoJki5BAA/file# [following]\n",
            "--2019-11-03 12:58:43--  https://uc67ec2ded65da0b5ae1fdee19b0.dl.dropboxusercontent.com/cd/0/inline/ArpPUtKM4Wb5qHbzTWkCkPVge-jgcfWIVHwzGp3Ij2SAVLTv7wgfvb0RwIKr6CjQMu-qU8xwOqOCnW98gbub_tEvJ19tTj1Z60joFfoJki5BAA/file\n",
            "Resolving uc67ec2ded65da0b5ae1fdee19b0.dl.dropboxusercontent.com (uc67ec2ded65da0b5ae1fdee19b0.dl.dropboxusercontent.com)... 162.125.1.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to uc67ec2ded65da0b5ae1fdee19b0.dl.dropboxusercontent.com (uc67ec2ded65da0b5ae1fdee19b0.dl.dropboxusercontent.com)|162.125.1.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2784447 (2.7M) [text/plain]\n",
            "Saving to: ‘train.ja?dl=0’\n",
            "\n",
            "train.ja?dl=0       100%[===================>]   2.66M  6.94MB/s    in 0.4s    \n",
            "\n",
            "2019-11-03 12:58:43 (6.94 MB/s) - ‘train.ja?dl=0’ saved [2784447/2784447]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "        誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。\n",
            "0         多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。\n",
            "1                        私 は テニス 部員 で す 。\n",
            "2                   エミ は 幸せ そう に 見え ま す 。\n",
            "3           この 事実 を 心 に 留め て お い て 下さ い 。\n",
            "4             彼女 は 私 たち の 世話 を し て くれ る 。\n",
            "...                                   ...\n",
            "49994             私 たち は その 結果 に 幻滅 し た 。\n",
            "49995  私 たち は 英語 で 少な から ず 誤り を 犯 し ま す 。\n",
            "49996              私 は 時間 を 持て余 し て い る 。\n",
            "49997       私 たち と 外 へ 昼食 に い き ま せ ん か 。\n",
            "49998               彼 は いらだ ち ながら 思 っ た 。\n",
            "\n",
            "[49999 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYjrZ3G7aeML",
        "colab_type": "text"
      },
      "source": [
        "## モデルの構築"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4kNdlhzmsHB",
        "colab_type": "code",
        "outputId": "68008a83-78e1-41aa-9f35-ea4f2d188842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Permute, Activation, Embedding, Dense, LSTM, concatenate, dot\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# エンコーダ\n",
        "encoder_inputs = Input(shape=(seqX_len,))\n",
        "\n",
        "emb_dim =256\n",
        "encoder_embedded = Embedding(en_vocab_size, emb_dim, mask_zero=True)(encoder_inputs)\n",
        "#　Embedding　単語を長さが一定のベクトルに変換します。\n",
        "#emb_dim は出力ベクトルの次元数です。\n",
        "                              \n",
        "hid_dim = 256\n",
        "encoded_seq, *encoder_states = LSTM(hid_dim, return_sequences=True, return_state=True)(encoder_embedded)\n",
        "# Embeddingの出力を、LTSMの入力として利用します。その結果が、符号化器（エンコーダ）の出力になります。\n",
        "\n",
        "# デコーダ\n",
        "decoder_inputs = Input(shape=(seqY_len,))\n",
        "decoder_embedding = Embedding(ja_vocab_size, emb_dim)\n",
        "decoder_embedded = decoder_embedding(decoder_inputs)\n",
        "decoder_lstm = LSTM(hid_dim, return_sequences=True, return_state=True)\n",
        "decoded_seq, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
        "\n",
        "\n",
        "# Attention\n",
        "score_dense = Dense(hid_dim)\n",
        "score = score_dense(decoded_seq)\n",
        "score = dot([score, encoded_seq], axes=(2,2))\n",
        "attention = Activation('softmax')(score)\n",
        "context = dot([attention, encoded_seq], axes=(2,1))\n",
        "concat = concatenate([context, decoded_seq], axis=2)\n",
        "\n",
        "att_dim = 256\n",
        "attention_dense = Dense(att_dim, activation='tanh')\n",
        "attentional = attention_dense(concat)\n",
        "output_dense = Dense(ja_vocab_size, activation='softmax')\n",
        "outputs = output_dense(attentional)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTr59RZFlox2",
        "colab_type": "text"
      },
      "source": [
        "## モデルの学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pJGdBk0mvFY",
        "colab_type": "code",
        "outputId": "dc048910-bb56-4bf2-8aef-66758fa4d84d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_target = np.hstack((y_train[:, 1:], np.zeros((len(y_train),1), dtype=np.int32)))\n",
        "\n",
        "model.fit([x_train, y_train], np.expand_dims(train_target, -1), batch_size=128, epochs=10, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 39200 samples, validate on 9800 samples\n",
            "Epoch 1/10\n",
            "39200/39200 [==============================] - 57s 1ms/sample - loss: 2.9385 - val_loss: 2.3038\n",
            "Epoch 2/10\n",
            "39200/39200 [==============================] - 52s 1ms/sample - loss: 2.1028 - val_loss: 1.9890\n",
            "Epoch 3/10\n",
            "39200/39200 [==============================] - 52s 1ms/sample - loss: 1.8443 - val_loss: 1.8104\n",
            "Epoch 4/10\n",
            "39200/39200 [==============================] - 52s 1ms/sample - loss: 1.6668 - val_loss: 1.6616\n",
            "Epoch 5/10\n",
            "39200/39200 [==============================] - 52s 1ms/sample - loss: 1.5219 - val_loss: 1.5368\n",
            "Epoch 6/10\n",
            "39200/39200 [==============================] - 52s 1ms/sample - loss: 1.3946 - val_loss: 1.4609\n",
            "Epoch 7/10\n",
            "39200/39200 [==============================] - 52s 1ms/sample - loss: 1.2828 - val_loss: 1.3794\n",
            "Epoch 8/10\n",
            "39200/39200 [==============================] - 52s 1ms/sample - loss: 1.1844 - val_loss: 1.3244\n",
            "Epoch 9/10\n",
            "39200/39200 [==============================] - 52s 1ms/sample - loss: 1.1007 - val_loss: 1.2737\n",
            "Epoch 10/10\n",
            "39200/39200 [==============================] - 52s 1ms/sample - loss: 1.0281 - val_loss: 1.2325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f15c8014e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrQt7FDvmci2",
        "colab_type": "text"
      },
      "source": [
        "## モデルによる文章の生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5gbYaVIBqe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# エンコーダ（学習時と同じ構成、学習したレイヤーを利用）\n",
        "encoder_model = Model(encoder_inputs, [encoded_seq]+encoder_states)\n",
        "\n",
        "# デコーダ\n",
        "decoder_states_inputs = [Input(shape=(hid_dim,)), Input(shape=(hid_dim,))]\n",
        "\n",
        "decoder_inputs = Input(shape=(1,))\n",
        "decoder_embedded = decoder_embedding(decoder_inputs)#学習済みEmbeddingレイヤーを利用\n",
        "decoded_seq, *decoder_states = decoder_lstm(decoder_embedded, initial_state=decoder_states_inputs)# 学習済みLSTMレイヤーを利用\n",
        "\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoded_seq] + decoder_states)\n",
        "\n",
        "# Attention\n",
        "encoded_seq_in, decoded_seq_in = Input(shape=(seqX_len, hid_dim)), Input(shape=(1, hid_dim))\n",
        "score = score_dense(decoded_seq_in)\n",
        "score = dot([score, encoded_seq_in], axes=(2,2))\n",
        "attention = Activation('softmax')(score)\n",
        "context = dot([attention, encoded_seq_in], axes=(2,1))\n",
        "concat = concatenate([context, decoded_seq_in], axis=2)\n",
        "attentional = attention_dense(concat)\n",
        "attention_outputs = output_dense(attentional)\n",
        "\n",
        "attention_model = Model([encoded_seq_in, decoded_seq_in], [attention_outputs, attention])\n",
        "\n",
        "def decode_sequence(input_seq, bos_eos, max_output_length = 1000):\n",
        "    encoded_seq, *states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = np.array(bos_eos[0])  # bos_eos[0]=\"<s>\"に対応するインデックス\n",
        "    output_seq = bos_eos[0][:]\n",
        "    attention_seq = np.empty((0,len(input_seq[0])))\n",
        "    \n",
        "    while True:\n",
        "        decoded_seq, *states_value = decoder_model.predict([target_seq] + states_value)\n",
        "        output_tokens, attention = attention_model.predict([encoded_seq, decoded_seq])\n",
        "        sampled_token_index = [np.argmax(output_tokens[0, -1, :])]\n",
        "        output_seq += sampled_token_index\n",
        "        attention_seq = np.append(attention_seq, attention[0], axis=0)\n",
        "        \n",
        "        if (sampled_token_index == bos_eos[1] or len(output_seq) > max_output_length):\n",
        "            break\n",
        "\n",
        "        target_seq = np.array(sampled_token_index)\n",
        "\n",
        "    return output_seq, attention_seq\n",
        "\n",
        "\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "detokenizer_en = dict(map(reversed, tokenizer_en.word_index.items()))\n",
        "detokenizer_ja = dict(map(reversed, tokenizer_ja.word_index.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyNMoQOvm1mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evalation(text_no):\n",
        "  input_seq = pad_sequences([x_test[text_no]], seqX_len, padding='post')\n",
        "  bos_eos = tokenizer_ja.texts_to_sequences([\"<s>\", \"</s>\"])\n",
        "\n",
        "  output_seq, attention_seq = decode_sequence(input_seq, bos_eos)\n",
        "\n",
        "  print('元の文:', ' '.join([detokenizer_en[i] for i in x_test[text_no]]))\n",
        "  print('生成文:', ' '.join([detokenizer_ja[i] for i in output_seq]))\n",
        "  print('正解文:', ' '.join([detokenizer_ja[i] for i in y_test[text_no]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izvxGqd-Y8h_",
        "colab_type": "code",
        "outputId": "fd015384-c632-4262-d7db-edad781a2e7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "evalation(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "元の文: <s> he is almost always at home . </s>\n",
            "生成文: <s> 彼 は いつ も 家 に い る 。 </s>\n",
            "正解文: <s> 彼 は ほとんど いつ も 家 に い る 。 </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUkAHTyCYROa",
        "colab_type": "code",
        "outputId": "b0e03db0-f896-4718-8b4d-d523bf00a2b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "evalation(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "元の文: <s> i always brush my coat when i come home . </s>\n",
            "生成文: <s> 私 は いつ も 帰 っ て くる の が いつ も 。 </s>\n",
            "正解文: <s> 私 は 帰宅 する と いつ も コート に ブラシ を かけ る 。 </s>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}